{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d7c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Data\n",
    "parser.add_argument(\n",
    "    '-N_Q', '--N_samples_Q', type=int, default=200, help='total number of target samples',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_P', '--N_samples_P', type=int, default=600, help='total number of prior samples',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_dim', type=int, help='dimension of input data',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_latent_dim', type=int, help='dimension of latent space',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_project_dim', type=int, help='dimension of PCA projected space on input',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-sample_latent', type=bool, default = False, help='True: sample in the latent space, False: sample in the physical space',\n",
    ")\n",
    "# Dataset property\n",
    "parser.add_argument(\n",
    "    '--dataset', type=str, default='Lorenz63', choices=['Lorenz63', 'Learning_gaussian', 'Mixture_of_gaussians', 'Mixture_of_gaussians2','Mixture_of_gaussians3','Mixture_of_gaussians4', 'Stretched_exponential', 'Learning_student_t', 'Mixture_of_student_t', 'Mixture_of_student_t_submnfld', 'Mixture_of_gaussians_submnfld','MNIST', 'CIFAR10', 'MNIST_switch', 'CIFAR10_switch', 'MNIST_ae', 'MNIST_ae_switch','CIFAR10_ae',  'Mixture_of_gaussians_submnfld_ae','BreastCancer', '1D_pts', '2D_pts','1D_dirac2gaussian', '1D_dirac2uniform',]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-y0', type=float, nargs=\"+\", default=[1.0,2.0, 2.0]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-beta', type=float, help='gibbs distribution of -|x|^\\beta',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-sigma_P', type=float, default=0.5, help='std of initial gaussian distribution',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-sigma_Q', type=float, default=0.5, help='std of target gaussian distribution',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-nu', type=float, help='df of target student-t distribution',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-interval_length', type=float, help='interval length of the uniform distribution',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-label', type=int, nargs=\"+\", help='class label of image data',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-pts_P', type=float, nargs=\"+\", default=[10.0,]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-pts_Q', type=float, nargs=\"+\", default=[0.0,]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-pts_P_2', type=float, nargs=\"+\", default=[0.0,]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-pts_Q_2', type=float, nargs=\"+\", default=[0.0,]\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--random_seed', type=int, default=0, help='random seed for data generator',\n",
    ")\n",
    "\n",
    "\n",
    "# (f, Gamma)-divergence\n",
    "parser.add_argument(\n",
    "    '--f', type=str, default='KL', choices=['KL', 'alpha', 'reverse_KL', 'JS'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-alpha', type=float, help='parameter value for alpha divergence',\n",
    ")    \n",
    "parser.add_argument(\n",
    "    '--formulation', type=str, default='DV', choices=['LT', 'DV'], help='LT or DV in case of f=KL, otherwise, keep LT',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--Gamma', type=str, default='Lipshitz', choices=['Lipshitz'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-L', type=float, default=1.0, help='Lipshitz constant: default=inf w/o constraint',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--reverse', type=bool, default=False, help='True -> D(Q|P), False -> D(P|Q)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--constraint', type=str, default='hard', choices=['hard', 'soft'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-lamda', type=float, default=100.0, help='coefficient on soft constraint',\n",
    ")\n",
    "\n",
    "\n",
    "# Neural Network definition <phi>\n",
    "parser.add_argument(\n",
    "    '-NN', '--NN_model', type=str, default='fnn', choices=['fnn', 'cnn', 'cnn-fnn'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_fnn_layers', type=int, nargs='+', default=[32,32,32], help='list of the number of FNN hidden layer units / the number of CNN feed-forward hidden layer units',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-N_cnn_layers', type=int, nargs='+', help='list of the number of CNN channels',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--activation_ftn', type=str, nargs='+', default=['relu',], choices=['relu', 'mollified_relu_cos3','mollified_relu_poly3','mollified_relu_cos3_shift','softplus', 'leaky_relu','elu', 'bounded_relu', 'bounded_elu'], help='[0]: for the fnn/convolutional layer, [1]: for the cnn feed-forward layer, [2]: for the LAST cnn feed-forward layer',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-eps', type=float, default = 0.5, help='Mollifier shape adjusting parameter when using mollified relu3 activations',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--N_conditions', type=int, default=1, help='number of classes for the conditional setting',\n",
    ")\n",
    "\n",
    "\n",
    "# training parameters\n",
    "parser.add_argument(\n",
    "    '-ep', '--epochs', type=int, default=1000, help='# updates for P',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-ep_nn', '--epochs_nn', type=int, default=3, help='# updates for NN to find phi*',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--optimizer', type=str, default='adam', choices=['sgd', 'adam',], help='optimizer for NN',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--ode_solver', type=str, choices=['forward_euler', 'AB2', 'AB3', 'AB4', 'AB5', 'ABM1', 'Heun', 'ABM2', 'ABM3', 'ABM4', 'ABM5', 'RK4', 'ode45' ], default='forward_euler', help='ode solver for particle ode',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-mobility', type=str, help='problem dependent mobility function\\nRecommendation: MNIST - bounded',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-lr_P_decay', type=str, choices=['rational', 'step',], help='delta t decay',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr_P', type=float, default=1.0, help='lr for P',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr_NN', type=float, default=0.001, help='lr for NN',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--exp_no', type=str, default='first_run', help='short experiment name under the same data',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mb_size_P', type=int, default=200, help='mini batch size for the moving distribution P',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mb_size_Q', type=int, default=200, help='mini batch size for the target distribution Q',\n",
    ")\n",
    "\n",
    "\n",
    "# save/display \n",
    "parser.add_argument(\n",
    "    '--save_iter', type=int, default=10, help='save results per each save_iter',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--plot_result', type=bool, default=True, help='True -> show plots',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--plot_intermediate_result', type=bool, default=False, help='True -> save intermediate plots',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc09466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # avoid tensorflow warning\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters --------------------------------------\n",
    "p, unknown = parser.parse_known_args()\n",
    "param = vars(p)\n",
    "\n",
    "if p.alpha:    \n",
    "    par = [p.alpha]\n",
    "    p.exptype = '%s=%05.2f-%s' % (p.f, p.alpha, p.Gamma)\n",
    "else: \n",
    "    par = []\n",
    "    p.exptype = '%s-%s' % (p.f, p.Gamma)\n",
    "if p.L == None:\n",
    "    p.expname = '%s_%s' % (p.exptype, 'inf')\n",
    "else:\n",
    "    p.expname = '%s_%.4f' % (p.exptype, p.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation ----------------------------------------\n",
    "from util.generate_data import generate_data\n",
    "p, X_, Y_, X_label, Y_label = generate_data(p)\n",
    "       \n",
    "if p.dataset in ['BreastCancer',]:\n",
    "    Q = tf.constant(X_/10.0, dtype=tf.float32) # constant\n",
    "    P = tf.Variable(Y_/10.0, dtype=tf.float32) # variable\n",
    "else:\n",
    "    Q = tf.constant(X_, dtype=tf.float32) # constant\n",
    "    P = tf.Variable(Y_, dtype=tf.float32) # variable\n",
    "    \n",
    "if p.N_conditions >1:\n",
    "    Q_label = tf.constant(X_label, dtype=tf.float32)\n",
    "    P_label = tf.constant(Y_label, dtype=tf.float32)\n",
    "    \n",
    "    label_idx_Q = [Q_label[:,n]==1 for n in range(p.N_conditions)]\n",
    "    label_idx_P = [P_label[:,n]==1 for n in range(p.N_conditions)]\n",
    "else:\n",
    "    Q_label, P_label = None, None\n",
    "    label_idx_Q, label_idx_P = None, None\n",
    "    \n",
    "\n",
    "data_par = {'P_label': P_label, 'Q_label': Q_label, 'mb_size_P': p.mb_size_P, 'mb_size_Q': p.mb_size_Q, 'N_samples_P': p.N_samples_P, 'N_samples_Q': p.N_samples_Q, 'label_idx_Q' : label_idx_Q, 'label_idx_P': label_idx_P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e60b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator learning  -----------------------------------------\n",
    "# Discriminator construction using Neural Network\n",
    "from util.construct_NN import check_nn_topology, initialize_NN, model\n",
    "\n",
    "N_fnn_layers, N_cnn_layers, p.activation_ftn = check_nn_topology(p.NN_model, p.N_fnn_layers, p.N_cnn_layers, p.N_dim, p.activation_ftn)\n",
    "\n",
    "NN_par = {'NN_model':p.NN_model, 'activation_ftn':p.activation_ftn, 'N_dim': p.N_dim, 'N_cnn_layers':N_cnn_layers, 'N_fnn_layers':N_fnn_layers, 'N_conditions': p.N_conditions, 'constraint': p.constraint, 'L': p.L, 'eps': p.eps}\n",
    "\n",
    "W, b = initialize_NN(NN_par)\n",
    "phi = model(NN_par)  # discriminator\n",
    "\n",
    "# scalar optimal value optimization for f-divergence\n",
    "nu = tf.Variable(0.0, dtype=tf.float32)\n",
    "\n",
    "parameters = {'W':W, 'b':b, 'nu':nu} # Learnable parameters for the discriminator phi\n",
    "\n",
    "# Train setting\n",
    "from util.train_NN import train_disc\n",
    "lr_NN = tf.Variable(p.lr_NN, trainable=False) # lr for training a discriminator function\n",
    "\n",
    "# (Discriminator) Loss ----------------------------------------------\n",
    "loss_par = {'f': p.f, 'formulation': p.formulation, 'par': par, 'reverse': p.reverse, 'lamda': p.lamda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transporting particles --------------------------------------------\n",
    "# ODE solver setting\n",
    "from util.transport_particles import calc_vectorfield, solve_ode\n",
    "dPs = []\n",
    "if p.ode_solver in ['forward_euler', 'AB2', 'AB3', 'AB4', 'AB5']:\n",
    "    aux_params = []\n",
    "else:\n",
    "    aux_params = {'parameters': parameters, 'phi': phi, 'Q': Q, 'lr_NN': lr_NN,'epochs_nn': p.epochs_nn, 'loss_par': loss_par, 'NN_par': NN_par, 'data_par': data_par, 'optimizer': p.optimizer}\n",
    "\n",
    "# Applying mobility to particles\n",
    "if p.mobility == 'bounded':\n",
    "    from util.construct_NN import bounded_relu  # mobility that bounding particles (For image data)\n",
    "        \n",
    "# Train setting\n",
    "lr_P_init = p.lr_P # Assume that deltat = deltat(t)\n",
    "if p.ode_solver == \"DOPRI5\": # deltat = deltat(x,t)\n",
    "    lr_P_init = [p.lr_P]*p.N_samples_P\n",
    "    # Low dimensional example=> rank 2, Image example=> rank 4\n",
    "    for i in range(1, tf.rank(P)):\n",
    "        lr_P_init = np.expand_dims(lr_P_init, axis=i)\n",
    "lr_P = tf.Variable(lr_P_init, trainable=False)\n",
    "lr_Ps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8329851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save & plot settings -----------------------------------------------\n",
    "# Metrics to calculate\n",
    "from util.evaluate_metric import calc_fid, calc_ke, calc_grad_phi\n",
    "trajectories = []\n",
    "vectorfields = []\n",
    "divergences = []\n",
    "KE_Ps = []\n",
    "FIDs = []\n",
    "\n",
    "# saving/plotting parameters\n",
    "if p.save_iter >= p.epochs:\n",
    "    p.save_iter = 1\n",
    "\n",
    "if p.plot_result == True:\n",
    "    from plot_result import plot_result\n",
    "\n",
    "p.expname = p.expname+'_%04d_%04d_%02d_%s' % (p.N_samples_Q, p.N_samples_P, p.random_seed, p.exp_no)\n",
    "filename = p.dataset+'/%s.pickle' % (p.expname)\n",
    "\n",
    "if p.plot_intermediate_result == True:\n",
    "    if 'gaussian' in p.dataset and 'Extension' not in p.dataset:\n",
    "         r_param = p.sigma_Q\n",
    "    elif 'student_t' in p.dataset:\n",
    "        r_param = p.nu\n",
    "    elif p.dataset == 'Extension_of_gaussian':\n",
    "        r_param = p.a\n",
    "    else:\n",
    "        r_param = None\n",
    "    \n",
    "# additional plots for simple low dimensional dynamics\n",
    "if p.N_dim == 1:\n",
    "    xx = np.linspace(-10, 10, 300)\n",
    "    xx = tf.constant(np.reshape(xx, (-1,1)), dtype=tf.float32)\n",
    "    phis = []\n",
    "elif p.N_dim == 2:#'2D' in p.dataset:\n",
    "    xx = np.linspace(-10, 10, 40)\n",
    "    yy = np.linspace(-10, 10, 40)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    xx = np.concatenate((np.reshape(XX, (-1,1)), np.reshape(YY, (-1,1))), axis=1)\n",
    "    xx = tf.constant(xx, dtype=tf.float32)\n",
    "    phis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd460c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ---------------------------------------------------------------\n",
    "import time \n",
    "t0 = time.time()\n",
    "\n",
    "for it in range(1, p.epochs+1): # Loop for updating particles P\n",
    "    parameters, current_loss, dW_norm = train_disc(parameters, phi, P, Q, lr_NN, p.epochs_nn, loss_par, NN_par, data_par, p.optimizer, print_vals=True)\n",
    "    \n",
    "    dPs.append( calc_vectorfield(phi, P, parameters, NN_par, loss_par, data_par) )\n",
    "    \n",
    "    if p.ode_solver == \"DOPRI5\": # deltat adust\n",
    "        P, dPs, dP, lr_P = solve_ode(P, lr_P, dPs, p.ode_solver, aux_params) # update P\n",
    "    else:\n",
    "        P, dPs, dP = solve_ode(P, lr_P, dPs, p.ode_solver, aux_params) # update P\n",
    "\n",
    "    if p.mobility == 'bounded':\n",
    "        P.assign(bounded_relu(P))\n",
    "     \n",
    "    lr_Ps.append(lr_P.numpy())\n",
    "    # adjust learning rates\n",
    "    #if it>=100:\n",
    "    #    lr_P = decay_learning_rate(lr_P, p.lr_P_decay, {'epochs': p.epochs-100, 'epoch': it-100, 'KE_P': KE_P})\n",
    "    \n",
    "    # save results\n",
    "    divergences.append(current_loss)\n",
    "    KE_P = calc_ke(dP, p.N_samples_P)\n",
    "    KE_Ps.append(KE_P)\n",
    "    grad_phi = calc_grad_phi(dP)\n",
    "    #print(\"grad\", grad_phi)\n",
    "    \n",
    "    if p.epochs<=100 or it%p.save_iter == 0:\n",
    "        if p.dataset in ['BreastCancer',]:\n",
    "            trajectories.append(P.numpy()*10)\n",
    "        else:\n",
    "            trajectories.append(P.numpy())\n",
    "        if np.prod(p.N_dim) < 500:\n",
    "            vectorfields.append(dP.numpy())\n",
    "        elif np.prod(p.N_dim) >= 784:  # image data\n",
    "            FIDs.append( calc_fid(pred=P.numpy(), real=Q.numpy()) )\n",
    "    \n",
    "    # display intermediate results\n",
    "    if it % (p.epochs/10) == 0:\n",
    "    #if it in [5, 50, 500, 1000, 2000, 3000, 4000, 5000]:\n",
    "        display_msg = 'iter %6d: loss = %.10f, norm of dW = %.2f, kinetic energy of P = %.10f, average learning rate for P = %.6f' % (it, current_loss, dW_norm, KE_P, tf.math.reduce_mean(lr_P).numpy())\n",
    "        if len(FIDs) > 0 :\n",
    "            display_msg = display_msg + ', FID = %.3f' % FIDs[-1]   \n",
    "        print(display_msg)\n",
    "        print(\"grad\", grad_phi)\n",
    "        \n",
    "        if p.plot_intermediate_result == True:\n",
    "            data = {'trajectories': trajectories, 'divergences': divergences, 'KE_Ps': KE_Ps, 'FIDs':FIDs, 'X_':X_, 'Y_':Y_, 'X_label':X_label, 'Y_label':Y_label, 'dt': lr_Ps, 'dataset': p.dataset, 'r_param': r_param, 'vectorfields': vectorfields, 'save_iter':p.save_iter}\n",
    "            if p.N_dim ==2:\n",
    "                data.update({'phi': phi, 'W':W, 'b':b, 'NN_par':NN_par})\n",
    "            plot_result(filename, intermediate=True, epochs = it, iter_nos = None, data = data, show=False)\n",
    "        \n",
    "        '''\n",
    "        if np.prod(p.N_dim) <= 2:\n",
    "            zz = phi(xx,None, W,b,NN_par).numpy()\n",
    "            zz = np.reshape(zz, -1)\n",
    "            phis.append(zz)\n",
    "        '''\n",
    "\n",
    "total_time = time.time() - t0\n",
    "print(f'total time {total_time:.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa28834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result ------------------------------------------------------\n",
    "import pickle\n",
    "if not os.path.exists(p.dataset):\n",
    "    os.makedirs(p.dataset)\n",
    "\n",
    "if '1D' in p.dataset:\n",
    "    X_ = np.concatenate((X_, np.zeros(shape=X_.shape)), axis=1)\n",
    "    Y_ = np.concatenate((Y_, np.zeros(shape=Y_.shape)), axis=1)\n",
    "    \n",
    "    trajectories = [np.concatenate((x, np.zeros(shape=x.shape)), axis=1) for x in trajectories]\n",
    "    vectorfields = [np.concatenate((x, np.zeros(shape=x.shape)), axis=1) for x in vectorfields]\n",
    "        \n",
    "param.update({'X_': X_, 'Y_': Y_, 'lr_Ps':lr_Ps,})\n",
    "result = {'trajectories': trajectories, 'vectorfields': vectorfields, 'divergences': divergences, 'KE_Ps': KE_Ps, 'FIDs': FIDs,}\n",
    "\n",
    "if p.dataset in ['BreastCancer',]:\n",
    "    np.savetxt(\"gene_expression_example/GPL570/\"+p.dataset+'/output_norm_dataset_dim_%d.csv' % p.N_dim, trajectories[-1], delimiter=\",\")\n",
    "        \n",
    "# Save trained data\n",
    "with open(filename,\"wb\") as fw:\n",
    "    pickle.dump([param, result] , fw)\n",
    "print(\"Results saved at:\", filename)\n",
    "\n",
    "# Plot final result\n",
    "if p.plot_result == True:\n",
    "    plot_result(filename, intermediate=False, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd28d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(trajectories[0][:,0],trajectories[0][:,1],trajectories[0][:,2])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dataset = np.load('lorenzdataset.npy')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(dataset[0,0:-1:5],dataset[1,0:-1:5],dataset[2,0:-1:5],s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e712d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "particlesystems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dcff6d82c76e93f8bf1a2a5a5959262afe2e0fbcc55797eb73e33c922868f9ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
